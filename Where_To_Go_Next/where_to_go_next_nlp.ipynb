{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning scraped WikiVoyage descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:06:18.620794Z",
     "start_time": "2019-12-23T06:06:16.990508Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm as tqdm  # progress bar for x in tqdm(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:06:18.650556Z",
     "start_time": "2019-12-23T06:06:18.623190Z"
    }
   },
   "outputs": [],
   "source": [
    "# open links\n",
    "with open(\"city_info_final.pkl\", 'rb') as picklefile: \n",
    "    city_info_final = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:06:18.683397Z",
     "start_time": "2019-12-23T06:06:18.653420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>city_and_country</th>\n",
       "      <th>score</th>\n",
       "      <th>cost/month</th>\n",
       "      <th>fun</th>\n",
       "      <th>safety</th>\n",
       "      <th>quality_of_life</th>\n",
       "      <th>walkability</th>\n",
       "      <th>happiness</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>wifi</th>\n",
       "      <th>friendly_to_foreigners</th>\n",
       "      <th>english</th>\n",
       "      <th>avg_trip_length_days</th>\n",
       "      <th>return_rate_percent</th>\n",
       "      <th>hotel_price_night</th>\n",
       "      <th>airbnb_price_night</th>\n",
       "      <th>visitors</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buenos-aires</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>buenos aires argentina</td>\n",
       "      <td>4.88</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>Okay</td>\n",
       "      <td>Good</td>\n",
       "      <td>Great</td>\n",
       "      <td>Good</td>\n",
       "      <td>Great</td>\n",
       "      <td>Okay</td>\n",
       "      <td>Good</td>\n",
       "      <td>Okay</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>[/@krausefx, /@aczuleta, /@alexanderjoo, /@sil...</td>\n",
       "      <td>/wiki/Buenos_Aires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bangkok</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>bangkok thailand</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Great</td>\n",
       "      <td>Good</td>\n",
       "      <td>Great</td>\n",
       "      <td>Great</td>\n",
       "      <td>Great</td>\n",
       "      <td>Okay</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>[/@remyp, /@manas, /@timrael, /@dimqen, /@dani...</td>\n",
       "      <td>/wiki/Bangkok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mexico-city</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>mexico city mexico</td>\n",
       "      <td>4.72</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>Okay</td>\n",
       "      <td>Good</td>\n",
       "      <td>Great</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Okay</td>\n",
       "      <td>Good</td>\n",
       "      <td>Okay</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>[/@rohit, /@nadiaronquillo, /@evelienal, /@bri...</td>\n",
       "      <td>/wiki/Mexico_City/Santa_Fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>canggu</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>canggu indonesia</td>\n",
       "      <td>4.69</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>Great</td>\n",
       "      <td>Good</td>\n",
       "      <td>Okay</td>\n",
       "      <td>Okay</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Great</td>\n",
       "      <td>Good</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>[/@tris, /@joytravels, /@guar47, /@mariebriand...</td>\n",
       "      <td>/wiki/Canggu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chiang-mai</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>chiang mai thailand</td>\n",
       "      <td>4.68</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>Great</td>\n",
       "      <td>Good</td>\n",
       "      <td>Great</td>\n",
       "      <td>Good</td>\n",
       "      <td>Okay</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Okay</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>[/@meedamian, /@zapperen, /@john, /@kymellis, ...</td>\n",
       "      <td>/wiki/Chiang_Mai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city    country        city_and_country  score  cost/month   fun  \\\n",
       "0  buenos-aires  Argentina  buenos aires argentina   4.88      1026.0  Good   \n",
       "1       bangkok   Thailand        bangkok thailand   4.73      1522.0  Good   \n",
       "2   mexico-city     Mexico      mexico city mexico   4.72      1493.0  Good   \n",
       "3        canggu  Indonesia        canggu indonesia   4.69      1389.0  Good   \n",
       "4    chiang-mai   Thailand     chiang mai thailand   4.68      1126.0  Good   \n",
       "\n",
       "  safety quality_of_life walkability happiness nightlife   wifi  \\\n",
       "0   Okay            Good       Great      Good     Great   Okay   \n",
       "1   Good            Good       Great      Good     Great  Great   \n",
       "2   Okay            Good       Great      Good      Good   Okay   \n",
       "3  Great            Good        Okay      Okay      Good   Good   \n",
       "4  Great            Good       Great      Good      Okay   Good   \n",
       "\n",
       "  friendly_to_foreigners english  avg_trip_length_days  return_rate_percent  \\\n",
       "0                   Good    Okay                  25.0                 16.0   \n",
       "1                  Great    Okay                   7.0                 18.0   \n",
       "2                   Good    Okay                  14.0                 14.0   \n",
       "3                  Great    Good                  28.0                 17.0   \n",
       "4                   Good    Okay                  28.0                 15.0   \n",
       "\n",
       "   hotel_price_night  airbnb_price_night  \\\n",
       "0               34.0                24.0   \n",
       "1               31.0                51.0   \n",
       "2               30.0                31.0   \n",
       "3               21.0                58.0   \n",
       "4               25.0                41.0   \n",
       "\n",
       "                                            visitors  \\\n",
       "0  [/@krausefx, /@aczuleta, /@alexanderjoo, /@sil...   \n",
       "1  [/@remyp, /@manas, /@timrael, /@dimqen, /@dani...   \n",
       "2  [/@rohit, /@nadiaronquillo, /@evelienal, /@bri...   \n",
       "3  [/@tris, /@joytravels, /@guar47, /@mariebriand...   \n",
       "4  [/@meedamian, /@zapperen, /@john, /@kymellis, ...   \n",
       "\n",
       "                         link  \n",
       "0          /wiki/Buenos_Aires  \n",
       "1               /wiki/Bangkok  \n",
       "2  /wiki/Mexico_City/Santa_Fe  \n",
       "3                /wiki/Canggu  \n",
       "4            /wiki/Chiang_Mai  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_info_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:06:19.439569Z",
     "start_time": "2019-12-23T06:06:19.352323Z"
    }
   },
   "outputs": [],
   "source": [
    "# open links\n",
    "with open(\"wiki_voyage_content.pkl\", 'rb') as picklefile: \n",
    "    wiki_voyage_content = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:06:20.217052Z",
     "start_time": "2019-12-23T06:06:20.211867Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "wiki_voyage_content_df = pd.DataFrame(wiki_voyage_content)\n",
    "wiki_voyage_content_df.columns=['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:06:20.647379Z",
     "start_time": "2019-12-23T06:06:20.635052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n Buenos Aires is the capital of Argentina.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n Bangkok (Thai: กรุงเทพฯ Krung Thep) is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n Santa Fe is in the western area of Mexico C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nCanggu is a beach area in South Bali, north ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n Chiang Mai (เชียงใหม่) is the hub of northe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  \\n Buenos Aires is the capital of Argentina.\\n...\n",
       "1  \\n Bangkok (Thai: กรุงเทพฯ Krung Thep) is the ...\n",
       "2  \\n Santa Fe is in the western area of Mexico C...\n",
       "3  \\nCanggu is a beach area in South Bali, north ...\n",
       "4  \\n Chiang Mai (เชียงใหม่) is the hub of northe..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_voyage_content_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T04:31:58.364127Z",
     "start_time": "2019-12-23T04:31:58.360707Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = wiki_voyage_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:06:33.398536Z",
     "start_time": "2019-12-23T06:06:29.222970Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, Word2Vec, Phrases\n",
    "from gensim.summarization import summarize\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.summarization.textcleaner import clean_text_by_word, get_sentences\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:06:33.419969Z",
     "start_time": "2019-12-23T06:06:33.400477Z"
    }
   },
   "outputs": [],
   "source": [
    "def keep_only_letters_and_numbers(doc):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(doc)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:06:33.437050Z",
     "start_time": "2019-12-23T06:06:33.425266Z"
    }
   },
   "outputs": [],
   "source": [
    "# lower, tokenize, ignoring tokens that are too short or too long, remove accent marks\n",
    "def process_doc(doc):\n",
    "    return simple_preprocess(str(doc), deacc=True, min_len=2, max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:06:33.449208Z",
     "start_time": "2019-12-23T06:06:33.442236Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize(doc):\n",
    "    lem = []\n",
    "    for token in doc:\n",
    "        lem.append(token.lemma_ if token.lemma_ != '-PRON-' else token.lower_)\n",
    "    return ' '.join(lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T06:06:33.458718Z",
     "start_time": "2019-12-23T06:06:33.452846Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_all_stopwords(doc, stopwords):\n",
    "    tokens = [token for token in doc if token not in stopwords]\n",
    "    \n",
    "    # remove empty list tokens\n",
    "    cleaned_tokens = [x for x in tokens if x != []]\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T04:33:50.812968Z",
     "start_time": "2019-12-23T04:33:34.836517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner', 'lemmatize']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "nlp.add_pipe(lemmatize, name='lemmatize')\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T04:33:50.836098Z",
     "start_time": "2019-12-23T04:33:50.814740Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv('news_stopwords_1k.csv')\n",
    "\n",
    "# gensim, spacy, github stopwords\n",
    "all_stopwords = list(set(list(STOP_WORDS) + list(STOPWORDS) + list(stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T04:33:50.859780Z",
     "start_time": "2019-12-23T04:33:50.838764Z"
    }
   },
   "outputs": [],
   "source": [
    "# add the names of the cities and countries to the stopwords list\n",
    "# we dont want named entities affecting the recommendations too much\n",
    "for place in list(city_info_final['city_and_country']):\n",
    "    all_stopwords.extend(place.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T04:34:44.384660Z",
     "start_time": "2019-12-23T04:34:44.379949Z"
    }
   },
   "outputs": [],
   "source": [
    "# process each doc\n",
    "tokenized_corpus = []\n",
    "for doc in tqdm(corpus):\n",
    "    tokenized_doc = []\n",
    "    tokenized_doc.append(\n",
    "            remove_all_stopwords(\n",
    "                nlp.pipe(\n",
    "                    process_doc(\n",
    "                        keep_only_letters_and_numbers(doc))), all_stopwords))\n",
    "    tokenized_corpus.append(tokenized_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-23T04:21:11.249970Z",
     "start_time": "2019-12-23T04:21:11.240976Z"
    }
   },
   "outputs": [],
   "source": [
    "# get rid of unnecessary triple list\n",
    "tokenized_corpus_final = []\n",
    "for i in range(len(tokenized_corpus)):\n",
    "    tokenized_corpus_final.append(tokenized_corpus[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final dataframe\n",
    "with open(f'tokenized_corpus_final2.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(tokenized_corpus_final, picklefile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
