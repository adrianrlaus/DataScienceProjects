{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T01:07:34.639310Z",
     "start_time": "2020-01-13T01:07:31.633101Z"
    }
   },
   "outputs": [],
   "source": [
    "# web scraping\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "\n",
    "# NLP\n",
    "from fuzzywuzzy import fuzz\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, \\\n",
    "    strip_multiple_whitespaces, strip_numeric, remove_stopwords\n",
    "import re\n",
    "\n",
    "# misc\n",
    "from collections import defaultdict, Counter\n",
    "import pickle\n",
    "from tqdm import tqdm # progess bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T01:07:34.654581Z",
     "start_time": "2020-01-13T01:07:34.646292Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_keywords(string):\n",
    "    CUSTOM_FILTERS = [lambda x: x.lower(), strip_tags, strip_punctuation, strip_multiple_whitespaces,\n",
    "                     strip_numeric, remove_stopwords]\n",
    "    return Counter(preprocess_string(string, CUSTOM_FILTERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T01:07:38.343062Z",
     "start_time": "2020-01-13T01:07:36.627069Z"
    }
   },
   "outputs": [],
   "source": [
    "# asks the user how many job descriptions they would like to find keywords for\n",
    "num_jobs = 0\n",
    "while num_jobs == 0:\n",
    "    try: \n",
    "        num_jobs = int(input(\"Enter the number of jobs: \\n\"))\n",
    "    except ValueError:\n",
    "        print('Not a valid entry.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T01:07:40.677937Z",
     "start_time": "2020-01-13T01:07:39.587430Z"
    }
   },
   "outputs": [],
   "source": [
    "# asks the user for the LinkedIn job urls\n",
    "urls = []\n",
    "for i in range(num_jobs):\n",
    "    urls.append(input(\"Paste job description URL: \\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T01:07:43.792537Z",
     "start_time": "2020-01-13T01:07:41.498110Z"
    }
   },
   "outputs": [],
   "source": [
    "# path to the chromedriver executable\n",
    "chromedriver = \"/Applications/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(chromedriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T01:07:45.369296Z",
     "start_time": "2020-01-13T01:07:45.238961Z"
    }
   },
   "outputs": [],
   "source": [
    "job_descriptions = ''\n",
    "for url in urls:\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(1)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        job_descriptions += soup.find(class_='description').text\n",
    "    except:\n",
    "        print('URL is invalid')\n",
    "        \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T01:07:47.761383Z",
     "start_time": "2020-01-13T01:07:47.754472Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find important keywords\n",
    "keyword_count = count_keywords(job_descriptions)\n",
    "sorted_keyword_count = \\\n",
    "    {key: value for key, value in sorted(keyword_count.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# Print keywords that occur more than once\n",
    "print('\\nImportant Keywords Are: \\n')\n",
    "for key, value in sorted_keyword_count.items():\n",
    "    if value > 1:\n",
    "        print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Forward:\n",
    ">**This is a very basic keyword counter, that only works for LinkedIn. I would like to generalize further, allowing different websites to be scraped.**<br><br>\n",
    "**To make this tool more robust, adding more `stopwords` specific to job descriptions and posts would be beneficial.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
